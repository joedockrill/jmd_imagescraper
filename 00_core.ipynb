{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jmd_imagescraper.core\n",
    "\n",
    "> Core image scraping functions for creating deep learning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# scraping\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from enum import Enum\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import uuid\n",
    "\n",
    "# other\n",
    "from PIL import Image as PImage\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from fastprogress.fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search filtering\n",
    "\n",
    "The scrape/search functions can use the following enums as filters for searches. Filtering is normally pretty good, so by default the results **should be** square photos as this is what's requested from DDG. Sometimes results may not be quite what you've requested (eg: you may get a bit of clipart or something more or less square but not exactly). No checks are actually performed on what comes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImgSize(Enum):\n",
    "  Cached=\"\"\n",
    "  Small=\"Small\"\n",
    "  Medium=\"Medium\"\n",
    "  Large=\"Large\"\n",
    "  Wallpaper=\"Wallpaper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Cached` as the image size (the default) returns the image cached by DuckDuckGo/Bing. This is a very decent size for deep learning purposes and is much more reliable to download from (no 404s, no hot-linking bans etc). Using any other size will return the original images from the source websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImgLayout(Enum):\n",
    "  All=\"\"\n",
    "  Square=\"Square\"\n",
    "  Tall=\"Tall\"\n",
    "  Wide=\"Wide\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defaults to `Square` everywhere because that's what your DL models want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImgType(Enum):\n",
    "  All=\"\"\n",
    "  Photo=\"photo\"\n",
    "  Clipart=\"clipart\"\n",
    "  Gif=\"gif\"\n",
    "  Transparent=\"transparent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defaults to `Photo` everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImgColor(Enum):\n",
    "  All=\"\"\n",
    "  Color=\"color\"\n",
    "  Monochrome=\"Monochrome\"\n",
    "  Red=\"Red\"\n",
    "  Orange=\"Orange\"\n",
    "  Yellow=\"Yellow\"\n",
    "  Green=\"Green\"\n",
    "  Blue=\"Blue\"\n",
    "  Purple=\"Purple\"\n",
    "  Pink=\"Pink\" \n",
    "  Brown=\"Brown\"\n",
    "  Black=\"Black\" \n",
    "  Gray=\"Gray\" \n",
    "  Teal=\"Teal\"\n",
    "  White=\"White\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably unlikely to be of much use to you but it's part of the API so I include it. You never know..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def duckduckgo_scrape_urls(keywords: str, max_results: int, \n",
    "                           img_size: ImgSize=ImgSize.Cached, \n",
    "                           img_type: ImgType=ImgType.Photo,\n",
    "                           img_layout: ImgLayout=ImgLayout.Square,\n",
    "                           img_color: ImgColor=ImgColor.All,\n",
    "                           timeout: Union[float, tuple]=None) -> list:\n",
    "  '''Scrapes URLs from DuckDuckGo image search. Returns list of URLs.'''\n",
    "  BASE_URL = 'https://duckduckgo.com/'\n",
    "  params = {\n",
    "    'q': keywords\n",
    "  };\n",
    "  results = 0\n",
    "  links = []\n",
    "\n",
    "  resp = requests.post(BASE_URL, data=params)\n",
    "  match = re.search(r'vqd=([\\d-]+)\\&', resp.text, re.M|re.I)\n",
    "  assert match is not None, \"Failed to obtain search token\"\n",
    "\n",
    "  HEADERS = {\n",
    "      'authority': 'duckduckgo.com',\n",
    "      'accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "      'sec-fetch-dest': 'empty',\n",
    "      'x-requested-with': 'XMLHttpRequest',\n",
    "      'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
    "      'sec-fetch-site': 'same-origin',\n",
    "      'sec-fetch-mode': 'cors',\n",
    "      'referer': 'https://duckduckgo.com/',\n",
    "      'accept-language': 'en-US,en;q=0.9',\n",
    "  }\n",
    "\n",
    "  filters = \"\"\n",
    "  if(img_size != ImgSize.Cached): filters +=  \"size:\" + img_size.name\n",
    "  filters += \",\"\n",
    "  if(img_type != ImgType.All): filters +=  \"type:\" + img_type.name\n",
    "  filters += \",\"\n",
    "  if(img_layout != ImgLayout.All): filters +=  \"layout:\" + img_layout.name\n",
    "  filters += \",\"\n",
    "  if(img_color != ImgColor.All): filters +=  \"color:\" + img_color.name\n",
    "  \n",
    "  PARAMS = (\n",
    "      ('l', 'us-en'),\n",
    "      ('o', 'json'),\n",
    "      ('q', keywords),\n",
    "      ('vqd', match.group(1)),\n",
    "      ('f', filters),\n",
    "      ('p', '1'),\n",
    "      ('v7exp', 'a'),\n",
    "  )\n",
    "\n",
    "  requestUrl = BASE_URL + \"i.js\"\n",
    "\n",
    "  while True:\n",
    "      while True:\n",
    "          try:\n",
    "              resp = requests.get(requestUrl, headers=HEADERS, params=PARAMS, timeout=timeout)\n",
    "              data = json.loads(resp.text)\n",
    "              break\n",
    "          except requests.exceptions.Timeout as e:\n",
    "              print(\"Timeout while trying to scrape URLs.\")\n",
    "          except ValueError as e:\n",
    "              print(\"Hit request throttle, sleeping and retrying\")\n",
    "              time.sleep(5)\n",
    "              continue\n",
    "\n",
    "      #result[\"thumbnail\"] is normally big enough for most purposes\n",
    "      #result[\"width\"], result[\"height\"] are for the full size img in result[\"image\"]\n",
    "      #result[\"image\"] url to full size img on orig site (so may be less reliable) \n",
    "      #result[\"url\"], result[\"title\"].encode('utf-8') from the page the img came from\n",
    "      \n",
    "      for result in data[\"results\"]:\n",
    "        if(img_size == ImgSize.Cached): links.append(result[\"thumbnail\"])\n",
    "        else:                           links.append(result[\"image\"])\n",
    "\n",
    "        if(max_results is not None):\n",
    "          if(len(links) >= max_results) : return links\n",
    "\n",
    "      if \"next\" not in data:\n",
    "          #no next page, all done\n",
    "          return links\n",
    "\n",
    "      requestUrl = BASE_URL + data[\"next\"]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing, this function will return up to 477 urls for a single search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "def display_img(url):\n",
    "    display(IPImage(url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tse1.mm.bing.net/th?id=OIP.LR-2HW7P9ENbMGJ7cZTVGwHaHL&pid=Api',\n",
       " 'https://tse4.mm.bing.net/th?id=OIP.jgAbDJb9lY-p0Q83Q2xsCgHaI0&pid=Api',\n",
       " 'https://tse4.mm.bing.net/th?id=OIP.4g2txn6PXyuTbEXcJPI2qQHaIE&pid=Api']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = duckduckgo_scrape_urls(\"happy clowns\", max_results=3)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://tse1.mm.bing.net/th?id=OIP.LR-2HW7P9ENbMGJ7cZTVGwHaHL&pid=Api\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_img(links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the kind of size you can expect by default. As you can see it should normally be sufficient for your needs.\n",
    "\n",
    "Since the parameters you use are likely to be the same across every image search within your dataset, if you plan on overriding the defaults, you can pass your parameters in using a dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://cdn3.volusion.com/9nxdj.fchy5/v/vspfiles/photos/WR-13710-2T.jpg?1528880561',\n",
       " 'http://4.bp.blogspot.com/-GKGVUan6I3w/UOQtWCzichI/AAAAAAAANs0/mxox-FdrnRA/s1600/019.jpg',\n",
       " 'http://www.hahastop.com/thumbsb/The_All_Purple_Dog_b.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_results\": 3,\n",
    "    \"img_size\":    ImgSize.Medium, \n",
    "    \"img_type\":    ImgType.Photo,\n",
    "    \"img_layout\":  ImgLayout.All,\n",
    "    \"img_color\":   ImgColor.Purple\n",
    "}\n",
    "\n",
    "links = duckduckgo_scrape_urls(\"puppies\", **params)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://4.bp.blogspot.com/-GKGVUan6I3w/UOQtWCzichI/AAAAAAAANs0/mxox-FdrnRA/s1600/019.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_img(links[1])\n",
    "# why? just why??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rmtree(path: Union[str, Path]):\n",
    "    '''Recursively delete a directory tree'''\n",
    "    path = Path(path); assert path.is_dir()\n",
    "    for p in reversed(list(path.glob('**/*'))):\n",
    "        if p.is_file():  p.unlink()\n",
    "        elif p.is_dir(): p.rmdir()\n",
    "    path.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `rmtree()` to scrub your downloaded images, either to create a new dataset or if you just want to \"reset\" and start over while experimenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def download_urls(path: Union[str, Path], links: list, uuid_names: bool=True, timeout: Union[float, tuple]=None) -> list:\n",
    "  '''Downloads urls to the given path. Returns a list of Path objects for files downloaded to disc.'''\n",
    "  if(len(links) == 0):\n",
    "    print(\"Nothing to download!\"); return\n",
    "\n",
    "  path = Path(path)\n",
    "  path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  print(\"Downloading results into\", path)\n",
    "  pbar = progress_bar(links)\n",
    "  pbar.comment = 'Images downloaded'\n",
    "\n",
    "  i = 1\n",
    "  mk_uniq = lambda : '_' + str(uuid.uuid4())[:8] if uuid_names else ''\n",
    "  mk_fp = lambda x: path/(str(x).zfill(3) + mk_uniq() + \".jpg\")\n",
    "  is_file = lambda x: len(list(path.glob(str(x).zfill(3) + '*.jpg'))) > 0\n",
    "    \n",
    "  while is_file(i): i += 1 # don't overwrite previous searches\n",
    "  \n",
    "  results = []\n",
    "    \n",
    "  for link in pbar:\n",
    "      try:\n",
    "        resp = requests.get(link, timeout=timeout)\n",
    "        fp = mk_fp(i)\n",
    "        fp.write_bytes(resp.content)\n",
    "\n",
    "        try:\n",
    "          img = PImage.open(fp)\n",
    "          img.verify()\n",
    "          img.close()\n",
    "          results.append(Path(fp))\n",
    "        except Exception as e:\n",
    "          # print(e)\n",
    "          print(fp, \"is invalid\")\n",
    "          fp.unlink()\n",
    "      except requests.exceptions.Timeout as e:\n",
    "        print(\"Timeout while trying to retrieve\", link)\n",
    "      except Exception as e:\n",
    "        # print(e)\n",
    "        print(\"Exception occured while retrieving\", link)\n",
    "        \n",
    "      i += 1\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files will be saved as 001.jpg, 002.jpg etc but images already present will not be overwritten, so you can run multiple searches for the same label (eg: different genres of orchid all under one 'orchid' label) and file numbering will carry on from the last one on disc. \n",
    "\n",
    "If `uuid_names` parameter is `True`, enough of a uuid is appended to the name of the file (like `001_4cda4d95.jpg`) to ensure filenames are unique across directories. This is for compatibility with tools like `fastai.vision.widgets.ImageClassifierCleaner` which can move images between folders and hence cause name clashes. This is the default everywhere.\n",
    "\n",
    "Downloaded files will be checked for validity so you should never end up with corrupt images or truncated downloads. (Let me know if anything duff gets through)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\purple\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/001_0e3cc95b.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/002_6e8b3e7a.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/purple/003_4fddf126.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path.cwd()/\"images\"\n",
    "download_urls(root/\"purple\", links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def duckduckgo_search(path: Union[str, Path], label: str, keywords: str, max_results: int=100,\n",
    "                           img_size: ImgSize=ImgSize.Cached, \n",
    "                           img_type: ImgType=ImgType.Photo,\n",
    "                           img_layout: ImgLayout=ImgLayout.Square,\n",
    "                           img_color: ImgColor=ImgColor.All, \n",
    "                           timeout: Union[float, tuple]=None,\n",
    "                           scrape_timeout: Union[float, tuple]=None,\n",
    "                           uuid_names: bool=True) -> list:\n",
    "  '''Run a DuckDuckGo search and download the images. Returns a list of Path objects for files downloaded to disc.'''\n",
    "  \n",
    "  print(\"Duckduckgo search:\", keywords)\n",
    "  links = duckduckgo_scrape_urls(keywords, max_results, img_size, img_type, img_layout, img_color, timeout=scrape_timeout)\n",
    "  return download_urls(Path(path)/label, links, uuid_names=uuid_names, timeout=timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: nice clowns\n",
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/001_6b99919b.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/002_8c1451d7.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/003_d8a0fef5.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_search(root, \"Nice\", \"nice clowns\", max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a list of all the images downloaded across multiple searches you can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: nice clowns\n",
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: scary clowns\n",
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Scary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duckduckgo search: mimes\n",
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Mime\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/007_6af54a70.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/008_c304d5ca.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/009_efb040f8.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/001_b63c3858.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/002_40398473.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/003_e801795a.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Mime/001_f66174ed.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Mime/002_ee152455.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Mime/003_32d7762d.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_results\": 3,\n",
    "    \"img_size\":    ImgSize.Cached, \n",
    "    \"img_type\":    ImgType.Photo,\n",
    "    \"img_layout\":  ImgLayout.Square,\n",
    "    \"img_color\":   ImgColor.All,\n",
    "    \"uuid_names\": True\n",
    "}\n",
    "\n",
    "imgs = []\n",
    "imgs.extend(duckduckgo_search(root, \"Nice\", \"nice clowns\", **params))\n",
    "imgs.extend(duckduckgo_search(root, \"Scary\", \"scary clowns\", **params))\n",
    "imgs.extend(duckduckgo_search(root, \"Mime\", \"mimes\", **params))\n",
    "imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CSV dataset\n",
    "\n",
    "If you want to create a very large dataset with a lot of images but don't want to store and distribute a very large file, you can create a CSV file containing URL/label pairs. Your users can then download the image files themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                           \n",
    "def save_urls_to_csv(path: Union[str, Path], label: str, keywords: str, max_results: int=100,\n",
    "                       img_size: ImgSize=ImgSize.Cached, \n",
    "                       img_type: ImgType=ImgType.Photo,\n",
    "                       img_layout: ImgLayout=ImgLayout.Square,\n",
    "                       img_color: ImgColor=ImgColor.All,\n",
    "                       timeout: Union[float, tuple]=None) -> None:\n",
    "  '''Run a search and concat the URLs to a CSV file'''\n",
    "  path = Path(path)\n",
    "  if(path.exists() == False):\n",
    "    df = pd.DataFrame(columns=[\"URL\", \"Label\"])\n",
    "    df.to_csv(path, index=False)\n",
    "    \n",
    "  urls = duckduckgo_scrape_urls(keywords, max_results, img_size, img_type, img_layout, img_color, timeout=timeout)\n",
    "  \n",
    "  rows = []\n",
    "  for url in urls: rows.append({\"URL\":url, \"Label\":label})\n",
    "    \n",
    "  df = pd.concat([pd.read_csv(path), pd.DataFrame(rows)]) \n",
    "  df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = root/\"clowns.csv\"\n",
    "save_urls_to_csv(csv, \"Nice\", \"nice clowns\", max_results=5)\n",
    "save_urls_to_csv(csv, \"Scary\", \"scary clowns\", max_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.uFX0ybAs0Hi...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.s3Ie8ax_Fa6...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://tse1.mm.bing.net/th?id=OIP.lwC5ho3Ta-T...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://tse4.mm.bing.net/th?id=OIP.glEf94S1eD0...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.n3504PAjzbN...</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.zMsnePdSfSb...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.yhDrJ18seBC...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://tse1.mm.bing.net/th?id=OIP.y5tm55MMKcW...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.MWOP-aLPv8D...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://tse3.mm.bing.net/th?id=OIP.AZyYLBgzuTA...</td>\n",
       "      <td>Scary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Label\n",
       "0  https://tse4.mm.bing.net/th?id=OIP.uFX0ybAs0Hi...   Nice\n",
       "1  https://tse4.mm.bing.net/th?id=OIP.s3Ie8ax_Fa6...   Nice\n",
       "2  https://tse1.mm.bing.net/th?id=OIP.lwC5ho3Ta-T...   Nice\n",
       "3  https://tse4.mm.bing.net/th?id=OIP.glEf94S1eD0...   Nice\n",
       "4  https://tse3.mm.bing.net/th?id=OIP.n3504PAjzbN...   Nice\n",
       "5  https://tse3.mm.bing.net/th?id=OIP.zMsnePdSfSb...  Scary\n",
       "6  https://tse3.mm.bing.net/th?id=OIP.yhDrJ18seBC...  Scary\n",
       "7  https://tse1.mm.bing.net/th?id=OIP.y5tm55MMKcW...  Scary\n",
       "8  https://tse3.mm.bing.net/th?id=OIP.MWOP-aLPv8D...  Scary\n",
       "9  https://tse3.mm.bing.net/th?id=OIP.AZyYLBgzuTA...  Scary"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_images_from_csv(path: Union[str, Path], csv: Union[str, Path], url_col: str=\"URL\", label_col: str=\"Label\", uuid_names: bool=True, timeout: Union[float, tuple]=None):\n",
    "    '''Download the URLs from a CSV file to the given path. Returns a list of Path objects for files downloaded to disc.'''\n",
    "    path = Path(path); csv = Path(csv);\n",
    "    \n",
    "    df = pd.read_csv(csv)\n",
    "    labels = df.Label.unique()\n",
    "    imgs = []\n",
    "    \n",
    "    for label in labels:\n",
    "        df_label = df.loc[df[label_col] == label]\n",
    "        urls = df_label[url_col].to_list()\n",
    "        imgs.extend(download_urls(path/label, urls, uuid_names=uuid_names, timeout=timeout))\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will (you've guessed it), download the image files from the CSV file we've just created. You can also supply column names if you want to use it on a CSV file created elsewhere with different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Nice\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:00<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results into C:\\Users\\Joe\\Documents\\GitHub\\jmd_imagescraper\\images\\Scary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:01<00:00 Images downloaded]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/010_9cbdb8a7.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/011_2f35c643.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/012_5af5d807.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/013_30a96f50.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Nice/014_b5eef117.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/004_7813f590.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/005_23d91904.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/006_50884c99.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/007_88334447.jpg'),\n",
       " Path('C:/Users/Joe/Documents/GitHub/jmd_imagescraper/images/Scary/008_b3da1cce.jpg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_images_from_csv(root, csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_imagecleaner.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
